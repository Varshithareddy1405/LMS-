{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM86o94zoQSnStbYXYZ1Snu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Varshithareddy1405/LMS-/blob/main/11%2C12_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4p-D8nxmXkP0"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_I= userdata.get('GOOGLE_API_I')\n",
        "genai.configure(api_key=GOOGLE_API_I)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "    text = text.replace('*', ' - ')\n",
        "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "Rkm3A1p7ZCxa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "client=genai.Client(api_key=GOOGLE_API_I)"
      ],
      "metadata": {
        "id": "3Hb6sr1aZZeW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL.Image\n",
        "import google.generativeai as genai\n",
        "img = PIL.Image.open('Image1.jpg')\n",
        "img\n",
        "\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content([\"Write a short, engaging blog post based on this picture. It should include a description of the meal in the photo and talk about my journey meal prepping.\", img],stream=True)\n",
        "response.resolve()"
      ],
      "metadata": {
        "id": "J-MOa4xRZ2xs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "ViXxzirQbXKS",
        "outputId": "36f9a1ba-7322-48f7-e7bb-a22e2b369309"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> ## My Meal Prep Journey: From Chaos to Deliciousness!\n> \n> This photo? That's my latest meal prep victory!  Two perfectly portioned containers brimming with a delicious teriyaki chicken and broccoli stir-fry, served over fluffy white rice.  The vibrant colours of the red peppers and the bright green broccoli make it almost too pretty to eat... almost!\n> \n> My journey with meal prepping hasn't always been this picture-perfect.  Honestly, it started with disastrous attempts at prepping enough food for the week, only to have it all go bad before I even got halfway through.  There were days of soggy salads, mushy vegetables, and a fridge that looked like a disaster zone.\n> \n> But I persevered! I learned to choose the right containers (hello, glass!), master the art of proper storage, and plan my meals ahead of time to minimize waste and maximize flavor.  The key was finding recipes that were both healthy and easy to batch-cook, like this teriyaki chicken. It's packed with protein, veggies, and just the right amount of deliciousness to keep me going throughout the week.\n> \n> Now, Sunday afternoons are my dedicated meal prep time. It's a little bit of work, but the payoff is HUGE.  Knowing I have healthy, delicious meals ready to go makes my week so much easier and less stressful.  Plus, it's incredibly rewarding to see these colorful containers lined up in my fridge - a visual reminder of my commitment to a healthier, happier me.\n> \n> So, are you ready to embark on your own meal prep journey?  Let me know in the comments if you have any questions!  And stay tuned for more delicious meal prep ideas.\n"
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Generate an accurate caption for this image.\", img])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "En-Kuh2Bcpyq",
        "outputId": "094f2781-a5d3-4f02-a9be-65fa0a3c7c54"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a caption for the image:\n",
            "\n",
            "**Option 1 (Concise):**\n",
            "\n",
            "> Healthy and delicious meal prep!  Chicken and broccoli with rice.\n",
            "\n",
            "**Option 2 (More descriptive):**\n",
            "\n",
            "> Two containers of perfectly portioned chicken and vegetable stir-fry over rice.  Perfect for a healthy lunch or dinner on the go!\n",
            "\n",
            "**Option 3 (Engaging):**\n",
            "\n",
            "> Meal prepping made easy! This chicken and broccoli stir-fry with rice is packed with flavor and nutrients.  What's your favorite healthy meal prep recipe? #mealprep #healthyfood #chickenstirfry #cleaneating\n",
            "\n",
            "\n",
            "Choose the option that best suits your needs and intended audience.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "image_path=\"girl.jpg\"\n",
        "image = Image.open(image_path)\n",
        "response=model.generate_content([\"Describe this image in detail.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "1PKHW8uRefdX",
        "outputId": "e435dd21-1339-492c-d10c-aa2c69b9b618"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a description of the image:\n",
            "\n",
            "Close-up view of a woman with shoulder-length, curly brown hair. \n",
            "\n",
            "\n",
            "She is smiling and gesturing with her right index finger, pointing towards something off-camera to the left. She's wearing a teal-colored, three-quarter sleeve top or tunic with a subtle gold print or pattern. The pattern appears to be small, repeated floral or paisley-like designs. The neckline is a simple, slightly open V-neck. Her arms are folded across her chest, with one hand gesturing.\n",
            "\n",
            "\n",
            "The woman has a warm, friendly expression. Her skin tone is medium, and she appears to have minimal makeup. The background is a plain, bright white, which makes the woman and her outfit stand out clearly. The overall impression is a casual, approachable, and possibly promotional or instructive image.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=model.generate_content([\"What emotions can you detect in this image?\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "rtuBAfjVgdzx",
        "outputId": "faccd39a-ee52-4424-a1e9-d0d7152fd0a0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The woman in the image appears to be expressing a combination of emotions, primarily:\n",
            "\n",
            "* **Happiness/Cheerfulness:** Her smile is genuine and bright, suggesting a positive and upbeat mood.\n",
            "* **Helpfulness/Guidance:** Her pointing gesture indicates a willingness to assist or direct someone.  She seems to be offering information or suggesting something.\n",
            "* **Confidence:**  Her posture and direct gaze convey self-assurance.\n",
            "\n",
            "\n",
            "It's difficult to definitively say if there are other subtle emotions present without more context, but these three are the most prominent.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path='quote.jpg'\n",
        "image = Image.open(image_path)\n",
        "response=model.generate_content([\"Extract and read the text from this image.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "nRNjJcvBhsO7",
        "outputId": "243d7d02-d559-4dc3-ef57-6622bc04c631"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's the text from the image:\n",
            "\n",
            "FAILURE is not the\n",
            "opposite of success\n",
            "it's PART OF\n",
            "SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Open an image (change 'logo.jpg' to your actual file)\n",
        "\n",
        "image_path = \"logo1.jpg\"\n",
        "\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Ask Gemini to recognize the brand/logo\n",
        "\n",
        "response = model.generate_content([\"Identify the brand or company associated with this logo.\", image])\n",
        "\n",
        "print(response.text)\n"
      ],
      "metadata": {
        "id": "P92_b8EmkFrC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7202220b-2b7b-40e4-cd17-ed9a9eb72479"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's the logo for **Amazon**.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"product.jpg\"\n",
        "\n",
        "image = Image.open(image_path)\n",
        "\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "response = model.generate_content([\"What product is shown in this image?\", image])\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ozD7Rz1BOgDk",
        "outputId": "7fbf87ff-08fe-4ea5-af38-faead8dbe434"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That's a pair of black over-ear headphones.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content([\"Suggest similar products to this one.\", image])\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "G22lsEMJPGQL",
        "outputId": "00e575a4-d26d-41ef-8cac-a7af46149d02"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some similar products to the pictured black over-ear headphones.  To give you the best suggestions, I need a little more information.  Are you looking for:\n",
            "\n",
            "* **Similar Style/Design:**  Over-ear, closed-back headphones with a similar aesthetic (sleek, minimalist, all black)?\n",
            "* **Similar Features:**  Noise-canceling, wireless, specific audio quality (e.g., bass-heavy), microphone?\n",
            "* **Similar Price Range:**  Are you looking for budget-friendly options, mid-range, or high-end headphones?\n",
            "* **Specific Brand:**  Do you prefer a particular headphone brand?\n",
            "\n",
            "\n",
            "However, based on the image alone, here are some general suggestions of similar over-ear headphones you might like:\n",
            "\n",
            "* **Sony WH-CH710N:**  Wireless, noise-canceling, known for good sound quality at a mid-range price point.\n",
            "* **Audio-Technica ATH-M50x:** Popular studio-quality headphones (wired) often favored for their balanced sound and durability.\n",
            "* **JBL Tune 760NC:** Wireless, noise-canceling, focuses on comfort and ease of use.\n",
            "* **Sennheiser HD 280 PRO:** Wired headphones; widely used in professional settings and well-regarded for their accurate sound reproduction.\n",
            "* **Anker Soundcore Life Q30:** Affordable wireless noise-canceling headphones.\n",
            "\n",
            "\n",
            "To help me narrow down the suggestions, please provide some of the details mentioned above.  Knowing your priorities (price, features, etc.) will make it easier to find the perfect match for you.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path=\"invoice.jpg\"\n",
        "image=Image.open(image_path)\n",
        "response=model.generate_content([\"Extract the price from this image.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "qwoA6D53P8G-",
        "outputId": "29c99983-1f33-4c4e-f511-49d135a48533"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The price of each item is $10.00.  The sub-total is $100.00, and the grand total, including a 10% tax, is also $100.00.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path=\"bicycle.jpg\"\n",
        "image=Image.open(image_path)\n",
        "response=model.generate_content([\"Identify all objects present in this image.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "LcvgKp6TSNbf",
        "outputId": "f625455e-d6c0-41f4-8001-78b600734d0a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a list of the objects present in the image:\n",
            "\n",
            "* **Two bicycles:** One is mostly black and yellow, the other is white.\n",
            "* **Two men:**  Riding the bicycles. One is wearing a blue shirt and camouflage shorts, the other a gray shirt and jeans and a red cap.\n",
            "* **A motorcycle:** Parked on the left side of the image.\n",
            "* **A building:** With a closed shop front (roll-up door) and a window.\n",
            "* **A man (in the background):** Sitting inside the building.\n",
            "* **Two chairs:** Visible inside the building.\n",
            "* **Street:** Wet asphalt road.\n",
            "* **Vegetation:** Some grass along the side of the road.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image=Image.open(\"items.jpg\")\n",
        "response=model.generate_content([\"Identify all objects present in this image.\",image])\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "E5zdle7xTdg5",
        "outputId": "ba126acd-dfa5-449a-88a8-aa406e93abf0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's a list of the objects in the image, categorized for clarity:\n",
            "\n",
            "**Countable Items (left side):**\n",
            "\n",
            "* Eggs (3)\n",
            "* Banana (1)\n",
            "* Olives (2)\n",
            "* Fries (a serving)\n",
            "* Burger (1)\n",
            "* Hot dog (1)\n",
            "* Apple (1)\n",
            "* Carrots (2)\n",
            "* Tomatoes (3)\n",
            "* Watermelon (1)\n",
            "\n",
            "\n",
            "**Uncountable Items (right side):**\n",
            "\n",
            "* Milk (a bottle)\n",
            "* Flour (a bag)\n",
            "* Salt (a pile)\n",
            "* Sugar (a bowl)\n",
            "* Jam (a jar)\n",
            "* Meat (slices)\n",
            "* Rice (a bowl)\n",
            "* Honey (a jar)\n",
            "* Tea (a cup)\n",
            "* Cheese (a slice)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxpcTGdSUL85",
        "outputId": "b72d8025-11cf-490f-cf16-c20cccf4d8e8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.11/dist-packages (15.0.0)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube-transcript-api) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "def get_youtube_transcript(video_url):\n",
        "\n",
        "    \"\"\"Fetches the transcript of a YouTube video.\"\"\"\n",
        "\n",
        "    video_id = video_url.split(\"v=\")[1].split(\"&\")[0]  # Extract video ID\n",
        "\n",
        "    transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
        "\n",
        "    full_text = \" \".join([t[\"text\"] for t in transcript])\n",
        "\n",
        "    return full_text\n",
        "\n",
        "# Example Usage\n",
        "\n",
        "video_url = \"https://www.youtube.com/watch?v=unYDoA8QGH0&list=PLWEpztHwA4ZT2QlHC74oIz4MsawcvE-QX\"\n",
        "\n",
        "video_transcript = get_youtube_transcript(video_url)\n",
        "\n",
        "print(\"Transcript:\\n\", video_transcript[:500])  # Show first 500 characters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKGOgErnU2u8",
        "outputId": "aea8a26f-0418-4035-eff7-21130c5a94ed"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript:\n",
            " hi guys today I'm going to introduce you what is machine learning uh these are my presentation content what is machine learning what are the different applications of machine learning different types of machine learning and how to build a machine learning system or model then various kinds of algorithms and later on in this series we are going to take a Hands-On you know case studies or doing programming for various kinds of up algorithms so what is machine learning so machine learning is nothin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_I= userdata.get('GOOGLE_API_I')\n",
        "genai.configure(api_key=GOOGLE_API_I)"
      ],
      "metadata": {
        "id": "SL5m4EYAVSMD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_video(text):\n",
        "\n",
        "    \"\"\"Summarizes the YouTube video transcript using Gemini AI.\"\"\"\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "    prompt = f\"Summarize the following YouTube video transcript:\\n\\n{text}\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text\n",
        "\n",
        "summary = summarize_video(video_transcript)\n",
        "\n",
        "print(\"Summary:\\n\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "GBQ4aQl3WfJ-",
        "outputId": "1e01fbda-c6d8-48ff-a407-316ae9778611"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            " This YouTube video provides an introduction to machine learning.  The presenter covers the definition of machine learning (learning from data to make predictions without explicit programming), its various applications (speech recognition, web search, recommendation systems, computer vision, fraud detection, and information retrieval), and its three main types: supervised (learning from labeled data), unsupervised (learning from unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties).  The video also explains the difference between classification (predicting categorical labels) and regression (predicting continuous values) within supervised learning, and touches upon techniques like clustering and dimensionality reduction in unsupervised learning.  Finally, it outlines the typical workflow of building a machine learning model, including data preprocessing (cleaning, scaling, encoding, feature selection), algorithm selection, model building, and evaluation.  The presenter promises future videos with hands-on case studies and programming examples of various algorithms.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_video_insights(text):\n",
        "\n",
        "    \"\"\"Extracts key insights from the YouTube video transcript.\"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "    prompt = f\"Extract the key takeaways and insights from this YouTube video:\\n\\n{text}\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text\n",
        "\n",
        "insights = extract_video_insights(video_transcript)\n",
        "\n",
        "print(\"Key Insights:\\n\",insights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "VA7rqR6vWj5L",
        "outputId": "c5e496db-1ad4-4e44-cce2-5f86a429a58c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key Insights:\n",
            " This YouTube video provides an introduction to machine learning. Here are the key takeaways and insights:\n",
            "\n",
            "**What is Machine Learning?**\n",
            "\n",
            "* **Core Concept:** Machine learning is about learning from data.  It's a subfield of artificial intelligence that allows computers to learn patterns and make predictions without explicit programming.  The process involves using algorithms to build models from training data (past experience).  These models can then be used to predict future outcomes.\n",
            "* **Arthur Samuel's Definition:** A field of study that gives computers the ability to learn without being explicitly programmed.\n",
            "* **Formal Definition:** A computer program is said to learn from experience (E) with respect to some task (T) and performance measure (P), if its performance at T, as measured by P, improves with experience E.\n",
            "\n",
            "**Types of Machine Learning:**\n",
            "\n",
            "* **Supervised Learning:** The training data is labeled (outcomes are known).  This is used for:\n",
            "    * **Classification:** Predicting categorical outcomes (e.g., spam/not spam, type of flower).\n",
            "    * **Regression:** Predicting continuous outcomes (e.g., house price, temperature).\n",
            "* **Unsupervised Learning:** The training data is unlabeled (outcomes are unknown).  This is used for:\n",
            "    * **Clustering:** Grouping similar data points (e.g., customer segmentation).\n",
            "    * **Dimensionality Reduction:** Reducing the number of variables while retaining important information.\n",
            "* **Reinforcement Learning:** An agent learns through trial and error, receiving rewards or penalties based on its actions in an environment (e.g., game playing, robotics).\n",
            "\n",
            "**Applications of Machine Learning:**\n",
            "\n",
            "The video highlights numerous applications, including:\n",
            "\n",
            "* Speech recognition (Siri, Google Assistant)\n",
            "* Web search engines\n",
            "* Recommendation systems\n",
            "* Computer vision (image and video analysis)\n",
            "* Information retrieval (searching large datasets)\n",
            "* Fraud detection\n",
            "\n",
            "**Building a Machine Learning Model (Workflow):**\n",
            "\n",
            "The process involves these steps:\n",
            "\n",
            "1. **Data Preprocessing:** Cleaning, scaling, encoding, and selecting features from the raw data.\n",
            "2. **Algorithm Selection:** Choosing an appropriate algorithm (e.g., decision tree, random forest, k-nearest neighbors) based on the problem type (classification, regression) and data characteristics.\n",
            "3. **Model Building:** Training the algorithm on the prepared data to create a predictive model.\n",
            "4. **Model Evaluation:** Assessing the model's performance using metrics like accuracy.  Building multiple models and comparing their performance is recommended.\n",
            "\n",
            "**Key Terms:**\n",
            "\n",
            "The video emphasizes understanding key terms like:\n",
            "\n",
            "* Features/Attributes/Measurements/Dimensions (columns, excluding the target variable)\n",
            "* Samples/Instances/Observations (rows)\n",
            "* Target Variable/Class Label/Response Variable (the outcome to be predicted, often the last column)\n",
            "\n",
            "\n",
            "The video concludes by encouraging viewers to practice building models using datasets like the Iris dataset, and promises future lessons on implementing the algorithms discussed.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_question_about_video(text, question):\n",
        "\n",
        "    \"\"\"Answers user questions about the YouTube video content.\"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "    prompt = f\"The following is a YouTube video transcript:\\n\\n{text}\\n\\nAnswer this question based on the content:\\n{question}\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text\n",
        "\n",
        "question = \"What is the main topic discussed in the video?\"\n",
        "\n",
        "answer = ask_question_about_video(video_transcript, question)\n",
        "\n",
        "print(\"Answer:\\n\",answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "84zWApgDX_-5",
        "outputId": "2a06a3e5-1184-4480-8780-df7b9ec4093d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 2301.21ms\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TooManyRequests",
          "evalue": "429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-1cc350f1e303>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"What is the main topic discussed in the video?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mask_question_about_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_transcript\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-1cc350f1e303>\u001b[0m in \u001b[0;36mask_question_about_video\u001b[0;34m(text, question)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"The following is a YouTube video transcript:\\n\\n{text}\\n\\nAnswer this question based on the content:\\n{question}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    836\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             _retry_error_helper(\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1159\u001b[0m             \u001b[0;31m# subclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mcore_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0;31m# Return the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTooManyRequests\u001b[0m: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text):\n",
        "\n",
        "    \"\"\"Performs sentiment analysis on the YouTube video transcript.\"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "    prompt = f\"Analyze the sentiment of this YouTube video transcript. Is it positive, negative, or neutral?\\n\\n{text}\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text\n",
        "\n",
        "sentiment = analyze_sentiment(video_transcript)\n",
        "\n",
        "print(\"Sentiment Analysis:\\n\", sentiment)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "_4psK3beYGYl",
        "outputId": "92c1459f-a4c8-4c3d-a134-03a316aa44ee"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid non-printable character U+00A0 (<ipython-input-26-78962f2fb979>, line 15)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-78962f2fb979>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    print(\"Sentiment Analysis:\\n\", sentiment)\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid non-printable character U+00A0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JObNZJhWYqVK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}